{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8b6c11",
   "metadata": {},
   "source": [
    "\n",
    "# Introducción a Redes Neuronales Artificiales\n",
    "\n",
    "Este cuaderno proporciona una introducción práctica a las redes neuronales artificiales, desde los conceptos básicos hasta la implementación con TensorFlow/Keras. Aprenderemos los fundamentos y haremos ejemplos de clasificación con diferentes conjuntos de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbdd49",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Fundamentos de Redes Neuronales\n",
    "\n",
    "### 1.1 Inspiración Biológica y Perceptrón\n",
    "\n",
    "Las redes neuronales artificiales están inspiradas en la estructura y funcionamiento del cerebro humano. La unidad básica es el **perceptrón**, que modela matemáticamente el comportamiento de una neurona:\n",
    "\n",
    "![Perceptrón](https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/ArtificialNeuronModel_english.png/600px-ArtificialNeuronModel_english.png)\n",
    "\n",
    "Un perceptrón recibe múltiples entradas (x₁, x₂, ..., xₙ), cada una asociada a un peso (w₁, w₂, ..., wₙ). La salida se calcula como:\n",
    "\n",
    "y = f(∑ wᵢxᵢ + b)\n",
    "\n",
    "Donde:\n",
    "- ∑ wᵢxᵢ es la suma ponderada de las entradas\n",
    "- b es un término de sesgo (bias)\n",
    "- f es una función de activación no lineal\n",
    "\n",
    "La función de activación introduce la no-linealidad que permite a las redes neuronales aprender patrones complejos. Sin esta no-linealidad, las redes neuronales serían equivalentes a un modelo lineal simple.\n",
    "\n",
    "### 1.2 Limitaciones del Perceptrón Simple\n",
    "\n",
    "El perceptrón simple solo puede representar funciones linealmente separables. El ejemplo clásico es la operación XOR, que no puede ser resuelta por un solo perceptrón:\n",
    "\n",
    "| x₁ | x₂ | XOR |\n",
    "|----|----|----|\n",
    "| 0  | 0  | 0  |\n",
    "| 0  | 1  | 1  |\n",
    "| 1  | 0  | 1  |\n",
    "| 1  | 1  | 0  |\n",
    "\n",
    "Un perceptrón simple solo puede dibujar una línea recta en el espacio de características. Para problemas como XOR, necesitamos poder dibujar fronteras de decisión más complejas.\n",
    "\n",
    "### 1.3 Redes Multicapa\n",
    "\n",
    "Para superar las limitaciones del perceptrón simple, conectamos múltiples perceptrones en capas, formando una **red neuronal multicapa**:\n",
    "\n",
    "![Red Neuronal](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/500px-Colored_neural_network.svg.png)\n",
    "\n",
    "Una red neuronal típica tiene:\n",
    "- Una capa de entrada: recibe los datos originales\n",
    "- Una o más capas ocultas: aprenden representaciones cada vez más abstractas\n",
    "- Una capa de salida: produce la predicción final\n",
    "\n",
    "Esta estructura permite aprender representaciones complejas y resolver problemas no lineales como XOR. Cada capa transforma los datos de entrada en una representación más útil para la tarea final.\n",
    "\n",
    "Lo que hace poderosas a las redes neuronales multicapa es su capacidad para aprender automáticamente las características importantes a partir de los datos, sin necesidad de diseñarlas manualmente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7353662",
   "metadata": {},
   "source": [
    "\n",
    "![img1](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN1.png)\n",
    "\n",
    "\n",
    "Consisten en una capa de entrada, varias capas ocultas y una capa de salida. Cada nodo de una capa está conectado a todos los demás nodos de la siguiente capa. Representa lo que estudiamos hace un momento, el perceptrón:\n",
    "\n",
    "![img2](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN2.png)\n",
    "\n",
    "Después de que cada perceptrón aplica los pesos obtenidos y se tiene la salida después de aplicar la función de activación entonces cada salida se convierte en la entrada para la siguiente capa. Los cálculos fluyen el diagrama de izquierda a derecha y la salida final se calcula realizando este procedimiento para todos los nodos. \n",
    "\n",
    "El objetivo de esta red neuronal profunda es aprender los pesos asociados a cada flecha de la primera gráfica, en otras palabras, consiste en la estimación de las siguientes matrices:\n",
    "\n",
    "![img3](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN3.png)\n",
    "\n",
    "En ese sentido, aprovechando el gráfico anterior, entendemos que la salida, para la red representada en esa figura, se calcula de la siguiente forma:\n",
    "\n",
    "$$y=f(f(f(x\\cdot W_1)\\cdot W_2)\\cdot W_3)$$\n",
    "\n",
    "En este caso, todos los perceptrones tienen la misma función de activación $f$. El sesgo no esta incluido en la fórmula anterior, pero podemos ignorarlo mientras concebimos la intuición detrás de estas redes neuronales.\n",
    "\n",
    "### Intuición sobre el cálculo\n",
    "\n",
    "Para entender mejor el cálculo, pensemos en un ejemplo sencillo con valores concretos:\n",
    "- Supongamos que tenemos un vector de entrada x = [0.5, 0.3]\n",
    "- La primera matriz de pesos W₁ podría ser [[0.1, 0.2], [0.3, 0.4]]\n",
    "- La función de activación f podría ser la función sigmoide: f(x) = 1/(1+e^(-x))\n",
    "\n",
    "El cálculo pasaría por estas etapas:\n",
    "1. Multiplicar x·W₁ = [0.5, 0.3]·[[0.1, 0.2], [0.3, 0.4]] = [0.14, 0.22]\n",
    "2. Aplicar la activación: f([0.14, 0.22]) = [0.535, 0.555]\n",
    "3. Este resultado se convierte en la entrada para la siguiente capa, y así sucesivamente\n",
    "\n",
    "Esta \"cascada\" de cálculos permite que la red aprenda representaciones cada vez más abstractas del dato original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbffbf",
   "metadata": {},
   "source": [
    "# Backpropagation: El Algoritmo que Revolucionó el Aprendizaje Profundo\n",
    "\n",
    "## Introducción\n",
    "\n",
    "El backpropagation (propagación hacia atrás) es el algoritmo central que permite a las redes neuronales aprender de manera eficiente. Desarrollado en la década de 1970 y popularizado en 1986 por Rumelhart, Hinton y Williams, este algoritmo resolvió uno de los problemas fundamentales en el campo: ¿cómo entrenar eficientemente redes neuronales multicapa?\n",
    "\n",
    "## Fundamentos conceptuales\n",
    "\n",
    "Para entender el backpropagation, primero debemos comprender qué problema resuelve. En una red neuronal:\n",
    "\n",
    "1. Los datos fluyen desde la entrada hasta la salida (forward pass)\n",
    "2. La red genera una predicción que se compara con el valor real\n",
    "3. Se calcula un error basado en esta diferencia\n",
    "4. **El desafío**: Determinar cómo modificar cada peso de la red para reducir este error\n",
    "\n",
    "El backpropagation proporciona un método matemáticamente elegante para calcular cómo cada peso contribuye al error final, permitiendo actualizar todos los pesos de manera óptima.\n",
    "\n",
    "## El algoritmo paso a paso\n",
    "\n",
    "### 1. Propagación hacia adelante (Forward Pass)\n",
    "\n",
    "- Los datos de entrada $X$ se introducen en la primera capa\n",
    "- Para cada capa $l$, calculamos:\n",
    "  - Suma ponderada: $Z^l = W^l \\cdot A^{l-1} + b^l$\n",
    "  - Activación: $A^l = f(Z^l)$ donde $f$ es la función de activación\n",
    "- La salida de la última capa es la predicción de la red $\\hat{Y}$\n",
    "\n",
    "### 2. Cálculo del error\n",
    "\n",
    "- Comparamos la predicción $\\hat{Y}$ con el valor real $Y$\n",
    "- Calculamos el error según la función de pérdida elegida\n",
    "  - Por ejemplo, error cuadrático medio: $E = \\frac{1}{2}(Y - \\hat{Y})^2$\n",
    "\n",
    "### 3. Propagación hacia atrás (Backward Pass)\n",
    "\n",
    "Esta es la esencia del algoritmo:\n",
    "\n",
    "- Calculamos el gradiente del error respecto a la salida: $\\delta^L = \\frac{\\partial E}{\\partial Z^L}$\n",
    "- Para cada capa, de la última a la primera:\n",
    "  - Calculamos el gradiente respecto a los pesos: $\\frac{\\partial E}{\\partial W^l} = \\delta^l \\cdot (A^{l-1})^T$\n",
    "  - Calculamos el gradiente respecto a los sesgos: $\\frac{\\partial E}{\\partial b^l} = \\delta^l$\n",
    "  - Propagamos el error a la capa anterior: $\\delta^{l-1} = (W^l)^T \\cdot \\delta^l \\odot f'(Z^{l-1})$\n",
    "\n",
    "Donde $\\odot$ representa el producto elemento a elemento (Hadamard) y $f'$ es la derivada de la función de activación.\n",
    "\n",
    "### 4. Actualización de pesos\n",
    "\n",
    "- Para cada peso y sesgo en la red:\n",
    "  - $W^l = W^l - \\eta \\cdot \\frac{\\partial E}{\\partial W^l}$\n",
    "  - $b^l = b^l - \\eta \\cdot \\frac{\\partial E}{\\partial b^l}$\n",
    "\n",
    "Donde $\\eta$ (eta) es la tasa de aprendizaje que controla la magnitud de los ajustes.\n",
    "\n",
    "## La regla de la cadena: El corazón del backpropagation\n",
    "\n",
    "El backpropagation se basa en la regla de la cadena del cálculo diferencial. Para un peso $w_{ij}$ en una capa intermedia, su contribución al error final se calcula como:\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{ij}} = \\frac{\\partial E}{\\partial a_j} \\cdot \\frac{\\partial a_j}{\\partial z_j} \\cdot \\frac{\\partial z_j}{\\partial w_{ij}}$$\n",
    "\n",
    "Esta fórmula muestra la elegancia del algoritmo:\n",
    "- $\\frac{\\partial E}{\\partial a_j}$ es la contribución de la activación $j$ al error\n",
    "- $\\frac{\\partial a_j}{\\partial z_j}$ es la derivada de la función de activación en el nodo $j$\n",
    "- $\\frac{\\partial z_j}{\\partial w_{ij}}$ es simplemente la entrada $i$ que llega al nodo $j$\n",
    "\n",
    "La clave está en que podemos calcular estos gradientes de manera recursiva, comenzando desde la capa final y retrocediendo.\n",
    "\n",
    "## Ejemplo numérico simplificado\n",
    "\n",
    "Consideremos una red neuronal simple con:\n",
    "- 2 entradas ($x_1$, $x_2$)\n",
    "- 1 capa oculta con 2 neuronas\n",
    "- 1 neurona de salida\n",
    "- Función de activación sigmoide: $f(x) = \\frac{1}{1+e^{-x}}$\n",
    "\n",
    "**Forward pass:**\n",
    "1. Entrada: $X = [0.5, 0.3]$\n",
    "2. Pesos primera capa: $W^1 = \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix}$\n",
    "3. Suma ponderada: $Z^1 = [0.14, 0.22]$\n",
    "4. Activación: $A^1 = [0.535, 0.555]$\n",
    "5. Pesos segunda capa: $W^2 = \\begin{bmatrix} 0.5 \\\\ 0.6 \\end{bmatrix}$\n",
    "6. Salida: $\\hat{Y} = 0.598$\n",
    "7. Valor real: $Y = 1$\n",
    "8. Error: $E = \\frac{1}{2}(1 - 0.598)^2 = 0.081$\n",
    "\n",
    "**Backward pass:**\n",
    "1. Gradiente en la salida: $\\delta^2 = \\frac{\\partial E}{\\partial Z^2} = (\\hat{Y} - Y) \\cdot f'(Z^2) = -0.402 \\cdot 0.241 = -0.097$\n",
    "2. Gradientes para $W^2$: $\\frac{\\partial E}{\\partial W^2} = \\delta^2 \\cdot A^1 = [-0.052, -0.054]$\n",
    "3. Propagación del error a la capa oculta: $\\delta^1 = W^2 \\cdot \\delta^2 \\odot f'(Z^1) = [-0.011, -0.013]$\n",
    "4. Gradientes para $W^1$: $\\frac{\\partial E}{\\partial W^1} = \\delta^1 \\cdot X = \\begin{bmatrix} -0.006 & -0.003 \\\\ -0.007 & -0.004 \\end{bmatrix}$\n",
    "\n",
    "**Actualización de pesos** (con $\\eta = 0.1$):\n",
    "1. $W^2 = \\begin{bmatrix} 0.5 \\\\ 0.6 \\end{bmatrix} - 0.1 \\cdot \\begin{bmatrix} -0.052 \\\\ -0.054 \\end{bmatrix} = \\begin{bmatrix} 0.505 \\\\ 0.605 \\end{bmatrix}$\n",
    "2. $W^1$ = actualización similar para cada peso\n",
    "\n",
    "## Derivación para el caso de múltiples salidas\n",
    "\n",
    "Para redes con múltiples salidas, el proceso es similar pero trabajamos con vectores de error. Para una función de pérdida $E$:\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W^l} = \\frac{\\partial E}{\\partial Z^l} \\cdot \\frac{\\partial Z^l}{\\partial W^l}$$\n",
    "\n",
    "Donde $\\frac{\\partial E}{\\partial Z^l}$ es el vector de sensibilidad $\\delta^l$ que indica cómo cambios en la entrada neta de cada neurona afectan el error total.\n",
    "\n",
    "Para la capa de salida, este vector se calcula como:\n",
    "\n",
    "$$\\delta^L = \\nabla_{\\hat{Y}}E \\odot f'(Z^L)$$\n",
    "\n",
    "Y para capas anteriores:\n",
    "\n",
    "$$\\delta^l = ((W^{l+1})^T \\cdot \\delta^{l+1}) \\odot f'(Z^l)$$\n",
    "\n",
    "Esta formulación vectorial permite implementar el algoritmo de manera eficiente utilizando operaciones matriciales.\n",
    "\n",
    "## Desafíos y soluciones\n",
    "\n",
    "### El problema del desvanecimiento del gradiente\n",
    "\n",
    "En redes profundas, los gradientes pueden hacerse extremadamente pequeños en las primeras capas, lo que ralentiza o detiene el aprendizaje.\n",
    "\n",
    "Matemáticamente, esto ocurre porque:\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W^1} = \\frac{\\partial E}{\\partial A^L} \\cdot \\frac{\\partial A^L}{\\partial Z^L} \\cdot \\frac{\\partial Z^L}{\\partial A^{L-1}} \\cdot ... \\cdot \\frac{\\partial A^2}{\\partial Z^2} \\cdot \\frac{\\partial Z^2}{\\partial A^1} \\cdot \\frac{\\partial A^1}{\\partial Z^1} \\cdot \\frac{\\partial Z^1}{\\partial W^1}$$\n",
    "\n",
    "Si las derivadas $\\frac{\\partial A^l}{\\partial Z^l}$ son pequeñas (como ocurre en los extremos de la función sigmoide), su producto se acerca a cero exponencialmente.\n",
    "\n",
    "**Soluciones:**\n",
    "- Funciones de activación como ReLU: $f(x) = \\max(0, x)$ cuya derivada es 1 para valores positivos\n",
    "- Inicialización cuidadosa de pesos (Xavier/Glorot, He)\n",
    "- Conexiones residuales (skip connections)\n",
    "- Normalización por lotes (batch normalization)\n",
    "\n",
    "### El problema de la explosión del gradiente\n",
    "\n",
    "Si las derivadas $\\frac{\\partial A^l}{\\partial Z^l}$ son grandes, el producto puede crecer exponencialmente.\n",
    "\n",
    "**Soluciones:**\n",
    "- Recorte de gradientes: limitar $\\|\\nabla_W E\\|$ a un umbral máximo\n",
    "- Regularización $L1/L2$: añadir términos $\\lambda\\|W\\|_1$ o $\\lambda\\|W\\|_2^2$ al error\n",
    "- Reducción de la tasa de aprendizaje\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "El backpropagation constituye la columna vertebral matemática del aprendizaje profundo. Combinando principios de cálculo diferencial, álgebra lineal y optimización, este algoritmo permite a las redes neuronales aprender representaciones complejas de manera eficiente.\n",
    "\n",
    "Su elegancia radica en que convierte un problema aparentemente intratable (ajustar millones de parámetros) en un proceso computacionalmente viable, abriendo las puertas a las poderosas aplicaciones de inteligencia artificial que vemos hoy en día."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25ed40",
   "metadata": {},
   "source": [
    "\n",
    "## ¿Por qué funcionan las redes?\n",
    "\n",
    "La esencia de las redes neuronales, por lo menos en esta versión inicial, consiste en la posibilidad de proyectar-transformar los registros de entrada en un espacio con mayor dimensión, con eso el proceso de clasificación se hace más sencillo, el siguiente gráfico ilustra esta situación:\n",
    "\n",
    "![img4](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN4.png)\n",
    "\n",
    "La proyección a otra dimensión permitió que hicieramos una separación como la siguiente:\n",
    "\n",
    "![img5](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN5.png)\n",
    "\n",
    "En resumen, las ANN son modelos de aprendizaje profundo muy flexibles pero potentes, permiten estimar aproximaciones a cualquier función compleja. Su aumento de popularidad se ha debido a tres razones:\n",
    "\n",
    "1. **Trucos inteligentes** que hicieron posible el entrenamiento de estos modelos\n",
    "   - Inicializaciones de pesos específicas\n",
    "   - Funciones de activación mejoradas como ReLU\n",
    "   - Técnicas de optimización avanzadas\n",
    "\n",
    "2. **Aumento en la potencia computacional**\n",
    "   - GPUs especializadas para cálculos matriciales\n",
    "   - Entrenamiento distribuido\n",
    "   - Optimizaciones a nivel de hardware\n",
    "\n",
    "3. **Grandes cantidades de datos de entrenamiento**\n",
    "   - Conjuntos de datos masivos para aprendizaje\n",
    "   - Técnicas de data augmentation\n",
    "   - Disponibilidad de datos pre-etiquetados\n",
    "\n",
    "Un resultado teórico importante es el **Teorema de Aproximación Universal**, que establece que una red neuronal feedforward con una sola capa oculta que contiene un número finito de neuronas puede aproximar cualquier función continua en un subconjunto compacto de Rⁿ, bajo ciertas suposiciones sobre la función de activación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a83dfe",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Aprendizaje en Redes Neuronales\n",
    "\n",
    "### 2.1 Funciones de Pérdida\n",
    "\n",
    "Para que una red neuronal aprenda, necesitamos una forma de medir cuán equivocada está. Las **funciones de pérdida** cuantifican la diferencia entre las predicciones de la red y los valores reales:\n",
    "\n",
    "- **Error Cuadrático Medio (MSE)**: Para problemas de regresión\n",
    "  MSE = (1/n) * ∑(y_pred - y_real)²\n",
    "\n",
    "  *Ventaja*: Penaliza fuertemente errores grandes\n",
    "  *Desventaja*: Muy sensible a valores atípicos\n",
    "\n",
    "- **Entropía Cruzada Binaria**: Para clasificación binaria\n",
    "  BCE = -(y_real * log(y_pred) + (1-y_real) * log(1-y_pred))\n",
    "\n",
    "  *Ventaja*: Muy efectiva para problemas de clasificación\n",
    "  *Desventaja*: Puede producir gradientes inestables\n",
    "\n",
    "- **Entropía Cruzada Categórica**: Para clasificación multiclase\n",
    "  CCE = -∑(y_real * log(y_pred))\n",
    "\n",
    "  *Ventaja*: Extiende BCE a múltiples clases\n",
    "  *Desventaja*: Requiere codificación one-hot de etiquetas\n",
    "\n",
    "La elección de la función de pérdida depende del tipo de problema (regresión vs. clasificación) y de las características específicas de los datos.\n",
    "\n",
    "### 2.2 Descenso de Gradiente\n",
    "\n",
    "El **descenso de gradiente** es un algoritmo de optimización que ajusta incrementalmente los pesos para minimizar la función de pérdida:\n",
    "\n",
    "1. Inicializar los pesos con valores aleatorios\n",
    "2. Calcular la predicción y la pérdida\n",
    "3. Calcular la derivada de la pérdida respecto a cada peso (gradiente)\n",
    "4. Ajustar los pesos en dirección opuesta al gradiente\n",
    "5. Repetir hasta converger\n",
    "\n",
    "La fórmula de actualización es:\n",
    "w = w - η * ∂L/∂w\n",
    "\n",
    "Donde η (eta) es la tasa de aprendizaje, un hiperparámetro que controla cuánto ajustamos los pesos en cada iteración:\n",
    "- Si η es muy pequeña: el aprendizaje es lento pero estable\n",
    "- Si η es muy grande: el aprendizaje es rápido pero puede diverger\n",
    "\n",
    "El descenso de gradiente puede implementarse de diferentes formas:\n",
    "- **Batch**: Utiliza todo el conjunto de datos\n",
    "- **Mini-batch**: Utiliza subconjuntos aleatorios de datos\n",
    "- **Estocástico**: Utiliza un solo ejemplo a la vez\n",
    "\n",
    "### 2.3 Retropropagación (Backpropagation)\n",
    "\n",
    "La **retropropagación** es un algoritmo eficiente para calcular gradientes en redes multicapa. Funciona propagando el error desde la salida hacia las capas anteriores:\n",
    "\n",
    "1. **Propagación hacia adelante**: Calcular la salida de la red para una entrada dada\n",
    "2. **Calcular el error**: Comparar la salida con el valor real usando la función de pérdida\n",
    "3. **Propagar hacia atrás**: Calcular el gradiente de la pérdida respecto a cada peso, capa por capa\n",
    "4. **Actualizar pesos**: Ajustar los pesos en dirección opuesta al gradiente\n",
    "\n",
    "Este proceso aprovecha la regla de la cadena del cálculo para calcular eficientemente cómo cada peso contribuye al error final.\n",
    "\n",
    "La retropropagación resuelve el problema fundamental de cómo asignar \"culpa\" del error a cada neurona en la red, permitiendo que todas las capas aprendan simultáneamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7faa735",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Implementación con Keras/TensorFlow\n",
    "\n",
    "Comenzaremos configurando nuestro entorno e importando las bibliotecas necesarias:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0c67de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListedColormap\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Datasets y métricas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_classification, make_moons, make_circles\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importaciones básicas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Datasets y métricas\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Configuración\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Eager execution: {tf.executing_eagerly()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebff15e",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Funciones de Visualización\n",
    "\n",
    "Para entender mejor el comportamiento de nuestras redes neuronales, definiremos algunas funciones de visualización que nos ayudarán a:\n",
    "\n",
    "1. Ver cómo la red divide el espacio de características (fronteras de decisión)\n",
    "2. Observar el proceso de aprendizaje a través del tiempo\n",
    "3. Analizar el rendimiento del modelo\n",
    "\n",
    "Estas visualizaciones son cruciales para desarrollar intuición sobre cómo funcionan las redes neuronales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28746e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_decision_boundary(model, X, y, title='Frontera de Decisión'):\n",
    "    \"\"\"\n",
    "    Visualiza la frontera de decisión creada por un modelo\n",
    "    sobre un conjunto de datos bidimensional.\n",
    "\n",
    "    Esta función nos permite ver cómo el modelo segmenta el espacio de características,\n",
    "    mostrando las regiones donde clasifica puntos como pertenecientes a cada clase.\n",
    "    \"\"\"\n",
    "    # Configurar el espacio de visualización\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    # Obtener predicciones del modelo para toda la grilla\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    probs = model.predict(grid)\n",
    "\n",
    "    if probs.shape[1] > 1:  # Caso multiclase\n",
    "        z = np.argmax(probs, axis=1).reshape(xx.shape)\n",
    "    else:  # Caso binario\n",
    "        z = probs.reshape(xx.shape)\n",
    "\n",
    "    # Crear la visualización\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, z, alpha=0.3, \n",
    "                 cmap=plt.cm.RdBu if probs.shape[1] <= 2 else plt.cm.viridis)\n",
    "\n",
    "    # Graficar los puntos de datos originales\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, \n",
    "               cmap=plt.cm.RdBu if len(np.unique(y)) <= 2 else plt.cm.viridis,\n",
    "               edgecolor='black', s=80, alpha=0.7)\n",
    "\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Característica 1', fontsize=12)\n",
    "    plt.ylabel('Característica 2', fontsize=12)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Visualiza la evolución de la pérdida y precisión durante el entrenamiento.\n",
    "\n",
    "    Esta función nos permite ver:\n",
    "    1. Si el modelo está aprendiendo (pérdida disminuye, precisión aumenta)\n",
    "    2. Si hay sobreajuste (rendimiento en validación empeora con el tiempo)\n",
    "    3. Cuándo el modelo converge\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Gráfico de pérdida\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validación')\n",
    "    plt.title('Evolución de la Pérdida', fontsize=14)\n",
    "    plt.xlabel('Épocas', fontsize=12)\n",
    "    plt.ylabel('Pérdida', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    # Gráfico de precisión\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "    plt.title('Evolución de la Precisión', fontsize=14)\n",
    "    plt.xlabel('Épocas', fontsize=12)\n",
    "    plt.ylabel('Precisión', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b23143",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Ejemplos Prácticos\n",
    "\n",
    "### 4.1 Clasificación Binaria\n",
    "\n",
    "Empezaremos con un problema simple de clasificación binaria usando datos sintéticos. Este ejemplo nos permitirá ver cómo una red neuronal aprende a separar dos clases.\n",
    "\n",
    "**¿Qué vamos a aprender?**\n",
    "- Cómo generar datos sintéticos para clasificación\n",
    "- Cómo construir un modelo básico de red neuronal\n",
    "- Cómo visualizar el proceso de aprendizaje\n",
    "- Cómo interpretar las métricas de evaluación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generamos datos sintéticos\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0,\n",
    "                           n_informative=2, random_state=42, n_clusters_per_class=1)\n",
    "\n",
    "# Visualizamos los datos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolor='black', s=50)\n",
    "plt.title('Datos de Clasificación Binaria', fontsize=16)\n",
    "plt.xlabel('Característica 1', fontsize=12)\n",
    "plt.ylabel('Característica 2', fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55322ac1",
   "metadata": {},
   "source": [
    "\n",
    "Observamos que los datos generados forman dos grupos que son bastante distinguibles, pero con cierto solapamiento. Ahora dividiremos los datos en conjuntos de entrenamiento y prueba para poder evaluar nuestro modelo correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ddb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividimos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Datos de entrenamiento: {X_train.shape}, Etiquetas: {y_train.shape}\")\n",
    "print(f\"Datos de prueba: {X_test.shape}, Etiquetas: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6083ec8",
   "metadata": {},
   "source": [
    "\n",
    "### Creación del modelo\n",
    "\n",
    "Ahora crearemos un modelo de red neuronal simple para clasificación binaria. Utilizaremos una arquitectura con:\n",
    "\n",
    "1. Una capa de entrada con 2 características\n",
    "2. Dos capas ocultas con 4 neuronas cada una y activación ReLU\n",
    "3. Una capa de salida con 1 neurona y activación sigmoide\n",
    "\n",
    "La función de activación **ReLU** (Rectified Linear Unit) se define como f(x) = max(0, x), y es una de las más utilizadas en capas ocultas por:\n",
    "- Su capacidad para introducir no-linealidad\n",
    "- Su eficiencia computacional\n",
    "- Su resistencia al problema de desvanecimiento del gradiente\n",
    "\n",
    "La función de activación **sigmoide** se define como f(x) = 1/(1+e^(-x)), y se utiliza en la capa de salida para problemas de clasificación binaria porque:\n",
    "- Produce valores entre 0 y 1, que pueden interpretarse como probabilidades\n",
    "- Su derivada es fácil de calcular: f'(x) = f(x) * (1 - f(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e1ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creamos un modelo simple de red neuronal\n",
    "model = Sequential([\n",
    "    Dense(4, input_shape=(2,), activation='relu', name='capa_oculta_1'),\n",
    "    Dense(4, activation='relu', name='capa_oculta_2'),\n",
    "    Dense(1, activation='sigmoid', name='capa_salida')\n",
    "])\n",
    "\n",
    "# Compilamos el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Mostramos el resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159d0df",
   "metadata": {},
   "source": [
    "\n",
    "El resumen anterior nos muestra:\n",
    "\n",
    "1. La arquitectura de la red: capas, número de neuronas y activaciones\n",
    "2. Los parámetros entrenables: pesos y sesgos que la red aprenderá\n",
    "3. El número total de parámetros, que es relativamente pequeño para esta red simple\n",
    "\n",
    "### Entrenamiento del modelo\n",
    "\n",
    "Ahora entrenaremos nuestro modelo utilizando el conjunto de datos de entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3024a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamos el modelo\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=32,\n",
    "                   epochs=50,\n",
    "                   validation_split=0.2,\n",
    "                   verbose=1)\n",
    "\n",
    "# Visualizamos el historial de entrenamiento\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b94cbe",
   "metadata": {},
   "source": [
    "\n",
    "Las gráficas de entrenamiento nos muestran:\n",
    "\n",
    "1. **Pérdida**: Cómo la función de pérdida (binary_crossentropy) disminuye con el tiempo\n",
    "2. **Precisión**: Cómo la proporción de predicciones correctas aumenta con el tiempo\n",
    "\n",
    "La diferencia entre las curvas de entrenamiento y validación nos da información sobre el posible sobreajuste. Si la curva de validación empeora mientras la de entrenamiento sigue mejorando, es una señal de que el modelo está memorizando el conjunto de entrenamiento en lugar de generalizar.\n",
    "\n",
    "### Evaluación del modelo\n",
    "\n",
    "Ahora evaluaremos el rendimiento de nuestro modelo en los datos de prueba, que no ha visto durante el entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluamos el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Precisión en datos de prueba: {accuracy:.4f}\")\n",
    "\n",
    "# Predicciones\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.show()\n",
    "\n",
    "# Métricas detalladas\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7f0a3",
   "metadata": {},
   "source": [
    "\n",
    "La matriz de confusión nos muestra:\n",
    "- **Verdaderos positivos (TP)**: Casos positivos correctamente identificados\n",
    "- **Falsos positivos (FP)**: Casos negativos incorrectamente clasificados como positivos\n",
    "- **Verdaderos negativos (TN)**: Casos negativos correctamente identificados\n",
    "- **Falsos negativos (FN)**: Casos positivos incorrectamente clasificados como negativos\n",
    "\n",
    "El informe de clasificación nos proporciona métricas más detalladas:\n",
    "- **Precisión**: TP / (TP + FP) - De todos los casos que el modelo clasifica como positivos, ¿cuántos son realmente positivos?\n",
    "- **Recall**: TP / (TP + FN) - De todos los casos positivos reales, ¿cuántos identificó el modelo?\n",
    "- **F1-score**: Media armónica de precisión y recall\n",
    "- **Support**: Número de ocurrencias de cada clase\n",
    "\n",
    "### Visualización de la frontera de decisión\n",
    "\n",
    "Finalmente, visualizamos la frontera de decisión que ha aprendido nuestro modelo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15774342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizamos la frontera de decisión\n",
    "plot_decision_boundary(model, X, y, 'Frontera de Decisión - Modelo Simple')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10144ec4",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Datos No Linealmente Separables\n",
    "\n",
    "Ahora trabajaremos con un conjunto de datos más complejo que no es linealmente separable. Esto demostrará el poder de las redes neuronales para aprender fronteras de decisión complejas.\n",
    "\n",
    "El conjunto de datos \"make_moons\" genera dos semicírculos entrelazados, un problema que no puede resolverse con un modelo lineal simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generamos datos en forma de lunas\n",
    "X_moons, y_moons = make_moons(n_samples=1000, noise=0.1, random_state=42)\n",
    "\n",
    "# Visualizamos los datos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap=plt.cm.RdBu, edgecolor='black', s=50)\n",
    "plt.title('Datos en Forma de Lunas', fontsize=16)\n",
    "plt.xlabel('Característica 1', fontsize=12)\n",
    "plt.ylabel('Característica 2', fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de883fc4",
   "metadata": {},
   "source": [
    "\n",
    "Estos datos tienen una estructura que claramente no puede separarse con una línea recta. Para este problema, necesitaremos una red neuronal con más capacidad (más capas y/o más neuronas) para aprender la frontera de decisión no lineal.\n",
    "\n",
    "Crearemos un modelo con más capas y más neuronas por capa:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividimos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_moons, y_moons, test_size=0.3, random_state=42)\n",
    "\n",
    "# Creamos un modelo con más capas\n",
    "model_moons = Sequential([\n",
    "    Dense(8, input_shape=(2,), activation='relu', name='capa_oculta_1'),\n",
    "    Dense(8, activation='relu', name='capa_oculta_2'),\n",
    "    Dense(8, activation='relu', name='capa_oculta_3'),\n",
    "    Dense(1, activation='sigmoid', name='capa_salida')\n",
    "])\n",
    "\n",
    "# Compilamos el modelo\n",
    "model_moons.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Mostramos el resumen del modelo\n",
    "model_moons.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92faca7b",
   "metadata": {},
   "source": [
    "\n",
    "Observa que hemos aumentado:\n",
    "1. El número de capas ocultas (de 2 a 3)\n",
    "2. El número de neuronas por capa (de 4 a 8)\n",
    "\n",
    "Esto da a la red más flexibilidad para aprender patrones complejos. Ahora entrenamos el modelo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece55702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamos el modelo\n",
    "history_moons = model_moons.fit(X_train, y_train,\n",
    "                              batch_size=32,\n",
    "                              epochs=50,\n",
    "                              validation_split=0.2,\n",
    "                              verbose=1)\n",
    "\n",
    "# Visualizamos el historial de entrenamiento\n",
    "plot_training_history(history_moons)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "loss, accuracy = model_moons.evaluate(X_test, y_test)\n",
    "print(f\"Precisión en datos de prueba: {accuracy:.4f}\")\n",
    "\n",
    "# Visualizamos la frontera de decisión\n",
    "plot_decision_boundary(model_moons, X_moons, y_moons, 'Frontera de Decisión - Datos de Lunas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d18b3",
   "metadata": {},
   "source": [
    "\n",
    "La frontera de decisión muestra la capacidad de la red neural para adaptarse a patrones no lineales. Observa cómo la frontera sigue la forma de las lunas, algo que un modelo lineal como regresión logística no podría hacer.\n",
    "\n",
    "Esta es una de las grandes ventajas de las redes neuronales: su capacidad para aprender automáticamente representaciones que capturan la estructura subyacente de los datos, incluso cuando esta estructura es compleja y no lineal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca6284",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Clasificación Multiclase\n",
    "\n",
    "Finalmente, veremos cómo abordar un problema de clasificación con más de dos clases. Los problemas de clasificación multiclase son comunes en aplicaciones del mundo real, como:\n",
    "\n",
    "- Reconocimiento de dígitos escritos a mano (10 clases)\n",
    "- Clasificación de especies de flores (múltiples especies)\n",
    "- Categorización de textos (múltiples categorías)\n",
    "\n",
    "Para este ejemplo, generaremos datos sintéticos con tres clases dispuestas en un patrón espiral:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para generar datos multiclase\n",
    "def make_multiclass_data(n_samples=1000, n_classes=3, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    X = np.zeros((n_samples, 2))\n",
    "    y = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    samples_per_class = n_samples // n_classes\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        ix = range(samples_per_class * i, samples_per_class * (i + 1))\n",
    "        r = np.linspace(0.0, 1, samples_per_class)\n",
    "        t = np.linspace(i * 4, (i + 1) * 4, samples_per_class) + np.random.normal(0, 0.2, samples_per_class)\n",
    "        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n",
    "        y[ix] = i\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Generamos datos multiclase\n",
    "X_multi, y_multi = make_multiclass_data(n_samples=1500, n_classes=3)\n",
    "\n",
    "# Visualizamos los datos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_multi[:, 0], X_multi[:, 1], c=y_multi, cmap=plt.cm.viridis, edgecolor='black', s=50)\n",
    "plt.title('Datos de Clasificación Multiclase', fontsize=16)\n",
    "plt.xlabel('Característica 1', fontsize=12)\n",
    "plt.ylabel('Característica 2', fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b95eb",
   "metadata": {},
   "source": [
    "\n",
    "### Modificaciones para clasificación multiclase\n",
    "\n",
    "Para la clasificación multiclase, necesitamos hacer dos cambios importantes:\n",
    "\n",
    "1. **Capa de salida**: Ahora necesitamos una neurona por cada clase (3 en este caso)\n",
    "2. **Función de activación**: Usamos softmax en lugar de sigmoid para la capa de salida\n",
    "\n",
    "La función de activación **softmax** convierte las salidas en probabilidades que suman 1 entre todas las clases:\n",
    "\n",
    "softmax(z)ᵢ = e^(zᵢ) / Σⱼ e^(zⱼ)\n",
    "\n",
    "Donde zᵢ es la salida para la clase i antes de la activación.\n",
    "\n",
    "También necesitamos convertir nuestras etiquetas a formato \"one-hot\" para el entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividimos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_multi, y_multi, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convertimos las etiquetas a formato one-hot\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train, 3)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, 3)\n",
    "\n",
    "# Ejemplo de codificación one-hot\n",
    "print(\"Primeras 5 etiquetas originales:\", y_train[:5])\n",
    "print(\"Primeras 5 etiquetas en formato one-hot:\")\n",
    "print(y_train_onehot[:5])\n",
    "\n",
    "# Creamos un modelo para clasificación multiclase\n",
    "model_multi = Sequential([\n",
    "    Dense(16, input_shape=(2,), activation='relu', name='capa_oculta_1'),\n",
    "    Dense(16, activation='relu', name='capa_oculta_2'),\n",
    "    Dense(3, activation='softmax', name='capa_salida')  # 3 clases\n",
    "])\n",
    "\n",
    "# Compilamos el modelo\n",
    "model_multi.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Mostramos el resumen del modelo\n",
    "model_multi.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamos el modelo\n",
    "history_multi = model_multi.fit(X_train, y_train_onehot,\n",
    "                              batch_size=32,\n",
    "                              epochs=50,\n",
    "                              validation_split=0.2,\n",
    "                              verbose=1)\n",
    "\n",
    "# Visualizamos el historial de entrenamiento\n",
    "plot_training_history(history_multi)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "loss, accuracy = model_multi.evaluate(X_test, y_test_onehot)\n",
    "print(f\"Precisión en datos de prueba: {accuracy:.4f}\")\n",
    "\n",
    "# Visualizamos la frontera de decisión\n",
    "plot_decision_boundary(model_multi, X_multi, y_multi, 'Frontera de Decisión - Multiclase')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb61230",
   "metadata": {},
   "source": [
    "\n",
    "Observa cómo la frontera de decisión ahora separa las tres clases. El modelo ha aprendido a identificar las regiones del espacio que corresponden a cada clase, creando un mapa de decisión que sigue el patrón espiral de los datos.\n",
    "\n",
    "La precisión final del modelo nos muestra cuán bien ha aprendido a generalizar para este problema multiclase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8d88b",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Ejercicios Guiados\n",
    "\n",
    "### 5.1 Comparación de Funciones de Activación\n",
    "\n",
    "Las funciones de activación son componentes críticos de las redes neuronales, ya que introducen la no-linealidad que permite a la red aprender patrones complejos. Vamos a comparar dos funciones de activación populares:\n",
    "\n",
    "1. **tanh (tangente hiperbólica)**:\n",
    "   - Rango: [-1, 1]\n",
    "   - Centrada en cero\n",
    "   - Tiene forma de S (sigmoide)\n",
    "\n",
    "2. **ReLU (Rectified Linear Unit)**:\n",
    "   - f(x) = max(0, x)\n",
    "   - Rango: [0, ∞)\n",
    "   - Computacionalmente eficiente\n",
    "   - Ayuda a mitigar el problema del desvanecimiento del gradiente\n",
    "\n",
    "Entrenaremos dos modelos idénticos pero con diferentes activaciones y compararemos su rendimiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creamos un modelo con activación tanh\n",
    "model_tanh = Sequential([\n",
    "    Dense(8, input_shape=(2,), activation='tanh', name='capa_oculta_1'),\n",
    "    Dense(8, activation='tanh', name='capa_oculta_2'),\n",
    "    Dense(1, activation='sigmoid', name='capa_salida')\n",
    "])\n",
    "\n",
    "model_tanh.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos brevemente para comparar\n",
    "history_tanh = model_tanh.fit(X_train[:500], y_train[:500],\n",
    "                            batch_size=32,\n",
    "                            epochs=30,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=0)\n",
    "\n",
    "# Creamos un modelo con activación relu\n",
    "model_relu = Sequential([\n",
    "    Dense(8, input_shape=(2,), activation='relu', name='capa_oculta_1'),\n",
    "    Dense(8, activation='relu', name='capa_oculta_2'),\n",
    "    Dense(1, activation='sigmoid', name='capa_salida')\n",
    "])\n",
    "\n",
    "model_relu.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos brevemente para comparar\n",
    "history_relu = model_relu.fit(X_train[:500], y_train[:500],\n",
    "                            batch_size=32,\n",
    "                            epochs=30,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparamos historiales de entrenamiento\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_tanh.history['loss'], label='tanh')\n",
    "plt.plot(history_relu.history['loss'], label='ReLU')\n",
    "plt.title('Comparación de Pérdida', fontsize=14)\n",
    "plt.xlabel('Épocas', fontsize=12)\n",
    "plt.ylabel('Pérdida', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico de precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_tanh.history['accuracy'], label='tanh')\n",
    "plt.plot(history_relu.history['accuracy'], label='ReLU')\n",
    "plt.title('Comparación de Precisión', fontsize=14)\n",
    "plt.xlabel('Épocas', fontsize=12)\n",
    "plt.ylabel('Precisión', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparamos fronteras de decisión\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Configurar visualización para tanh\n",
    "plt.subplot(1, 2, 1)\n",
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "z_tanh = model_tanh.predict(grid).reshape(xx.shape)\n",
    "plt.contourf(xx, yy, z_tanh, alpha=0.3, cmap=plt.cm.RdBu)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolor='black', s=20)\n",
    "plt.title('Frontera con Tanh', fontsize=14)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "# Configurar visualización para ReLU\n",
    "plt.subplot(1, 2, 2)\n",
    "z_relu = model_relu.predict(grid).reshape(xx.shape)\n",
    "plt.contourf(xx, yy, z_relu, alpha=0.3, cmap=plt.cm.RdBu)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolor='black', s=20)\n",
    "plt.title('Frontera con ReLU', fontsize=14)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05999ba5",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 Preguntas de Reflexión\n",
    "\n",
    "Ahora que hemos experimentado con diferentes modelos y conjuntos de datos, reflexionemos sobre lo aprendido:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070afea7",
   "metadata": {},
   "source": [
    "\n",
    "PREGUNTAS DE REFLEXIÓN:\n",
    "\n",
    "1. ¿Qué diferencias notaste entre las fronteras de decisión creadas por el \n",
    "   modelo simple (1 capa) y el modelo más complejo (3 capas)?\n",
    "\n",
    "2. ¿Cómo afectó el uso de diferentes funciones de activación (tanh vs ReLU) \n",
    "   al proceso de entrenamiento y a las fronteras de decisión?\n",
    "\n",
    "3. ¿Por qué el modelo multiclase utiliza softmax como activación en la \n",
    "   última capa en lugar de sigmoid?\n",
    "\n",
    "4. ¿Qué hipótesis puedes formular sobre la relación entre la complejidad \n",
    "   del modelo y su capacidad para ajustarse a datos no lineales?\n",
    "\n",
    "5. Si tuvieras que diseñar un modelo para un conjunto de datos más complejo,\n",
    "   ¿qué cambios harías en la arquitectura de la red?\n",
    "\n",
    "6. ¿En qué situaciones podrías estar frente a un caso de sobreajuste? \n",
    "   ¿Cómo lo identificarías y qué técnicas podrías usar para mitigarlo?\n",
    "\n",
    "7. ¿Qué otras funciones de activación conoces y en qué casos serían útiles?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917da145",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Conclusiones y Próximos Pasos\n",
    "\n",
    "En este cuaderno hemos:\n",
    "\n",
    "1. **Aprendido los fundamentos** de las redes neuronales artificiales:\n",
    "   - Perceptrón y sus limitaciones\n",
    "   - Redes multicapa como solución\n",
    "   - Funciones de activación y su importancia\n",
    "\n",
    "2. **Entendido el proceso de aprendizaje**:\n",
    "   - Funciones de pérdida\n",
    "   - Descenso de gradiente\n",
    "   - Backpropagation\n",
    "\n",
    "3. **Implementado modelos de clasificación** usando Keras:\n",
    "   - Clasificación binaria\n",
    "   - Datos no lineales\n",
    "   - Clasificación multiclase\n",
    "\n",
    "4. **Visualizado e interpretado resultados**:\n",
    "   - Fronteras de decisión\n",
    "   - Evolución del entrenamiento\n",
    "   - Métricas de rendimiento\n",
    "\n",
    "5. **Comparado diferentes configuraciones**:\n",
    "   - Arquitecturas\n",
    "   - Funciones de activación\n",
    "\n",
    "### Conceptos clave a recordar:\n",
    "\n",
    "- Las redes neuronales están compuestas por capas de neuronas interconectadas\n",
    "- El aprendizaje consiste en ajustar los pesos de las conexiones\n",
    "- La capacidad de las redes depende de su arquitectura (número de capas y neuronas)\n",
    "- Las funciones de activación introducen no-linealidad, permitiendo aprender patrones complejos\n",
    "- El sobreajuste ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento\n",
    "\n",
    "### Próximos pasos para seguir aprendiendo:\n",
    "\n",
    "- **Arquitecturas más avanzadas**: Redes convolucionales (CNN) para imágenes, redes recurrentes (RNN) para secuencias\n",
    "- **Técnicas de regularización**: Dropout, regularización L1/L2, early stopping\n",
    "- **Optimización de hiperparámetros**: Búsqueda de la mejor configuración\n",
    "- **Transfer learning**: Utilizar modelos pre-entrenados\n",
    "- **Interpretabilidad**: Entender cómo toma decisiones la red neuronal\n",
    "\n",
    "### Recursos adicionales:\n",
    "\n",
    "- [TensorFlow Documentation](https://www.tensorflow.org/guide)\n",
    "- [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) por François Chollet\n",
    "- [3Blue1Brown Neural Networks](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - Excelentes visualizaciones\n",
    "- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) por Michael Nielsen\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
